{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7178bd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# import pandas as pd\n",
    "import librosa\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import torch\n",
    "import torchaudio\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b80bd2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.load(\"data/features/x_1_3.npy\")\n",
    "y=np.load(\"data/features/y_1_3.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a28ff82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Shape: (117052, 43, 39)\n",
      "Test Data Shape: (29264, 43, 39)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "print(\"Training Data Shape:\", x_train.shape)\n",
    "print(\"Test Data Shape:\", x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "857456a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape= (43,39)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7697de1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class SpeakerCNN(nn.Module):\n",
    "    def __init__(self, input_shape, no_speakers, dropout_rate=0.7):\n",
    "        super(SpeakerCNN, self).__init__()\n",
    "        \n",
    "        # Unpack input shape dimensions\n",
    "        self.time_frames, self.mfcc_features = input_shape  # Example: input_shape=(43,39)\n",
    "\n",
    "        # First convolution block\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "\n",
    "        # Second convolution block\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "\n",
    "        # Third convolution block\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.pool3 = nn.MaxPool2d(2)\n",
    "\n",
    "        # Calculate the output shape after 3 pooling layers\n",
    "        conv_out_time = self._calculate_output_dim(self.time_frames, 3)\n",
    "        conv_out_features = self._calculate_output_dim(self.mfcc_features, 3)\n",
    "        flattened_dim = 128 * conv_out_time * conv_out_features\n",
    "\n",
    "        # Dropout for regularization (tunable)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(flattened_dim, 256)\n",
    "        self.fc2 = nn.Linear(256, no_speakers)\n",
    "\n",
    "    def _calculate_output_dim(self, size, num_pools):\n",
    "        # Calculates the output dimension after a series of MaxPool2d(2)\n",
    "        for _ in range(num_pools):\n",
    "            size = size // 2\n",
    "        return size\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x expected shape: [batch_size, time_frames, mfcc_features]\n",
    "        x = x.unsqueeze(1)  # add channel dimension\n",
    "\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.pool3(x)\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "846f1a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "model =SpeakerCNN(input_shape,no_speakers=51)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "85f2e00b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpeakerCNN(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (dropout): Dropout(p=0.7, inplace=False)\n",
      "  (fc1): Linear(in_features=2560, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=51, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "04826e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_tensor = torch.tensor(x_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "x_test_tensor = torch.tensor(x_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e2e90894",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "train_dataset = TensorDataset(x_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(x_test_tensor, y_test_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "549f2958",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Early stopping setup\n",
    "patience = 20\n",
    "best_val_loss = float('inf')\n",
    "epochs_no_improve = 0\n",
    "num_epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cfe5200c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SpeakerCNN(\n",
       "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (fc1): Linear(in_features=2560, out_features=256, bias=True)\n",
       "  (fc2): Linear(in_features=256, out_features=51, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "print(device)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f96eec6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"best_model_state_3_sec.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "17191c56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.1953, -1.0747, -1.3090,  ...,  1.5689,  0.4800,  1.6789],\n",
       "         [ 0.4530, -0.9632, -0.5165,  ...,  1.5689,  0.4800,  1.6789],\n",
       "         [ 0.5668, -0.5311,  0.2347,  ...,  1.5689,  0.4800,  1.6789],\n",
       "         ...,\n",
       "         [-1.5110, -1.3076,  0.0838,  ...,  0.2059, -0.9821, -1.8322],\n",
       "         [-1.6919, -1.1217,  0.0286,  ..., -0.8351, -0.4039, -1.0808],\n",
       "         [-1.7599, -1.0059,  0.2803,  ..., -1.2967,  0.1420, -0.0318]]),\n",
       " tensor(14))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_tensor[3],y_test_tensor[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a22b2901",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpeakerCNN(\n",
       "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (dropout): Dropout(p=0.7, inplace=False)\n",
       "  (fc1): Linear(in_features=2560, out_features=256, bias=True)\n",
       "  (fc2): Linear(in_features=256, out_features=51, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "07d98869",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss = 0\n",
    "correct = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec56d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.5142 | Val Acc: 0.8246\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "for inputs, labels in valid_loader:\n",
    "    inputs, labels = inputs.to(device), labels.to(device)\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "    val_loss += loss.item() * inputs.size(0)\n",
    "    preds = outputs.argmax(dim=1)\n",
    "    correct += (preds == labels).sum().item()\n",
    "\n",
    "epoch_val_loss = val_loss / len(test_dataset)\n",
    "epoch_val_acc = correct / len(test_dataset)\n",
    "\n",
    "# Print epoch info\n",
    "print(f\"Val Loss: {epoch_val_loss:.4f} | Val Acc: {epoch_val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5000c483",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speech",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
