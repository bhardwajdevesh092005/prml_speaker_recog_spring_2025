{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ic_f2Zxx26C0"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import librosa\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_file= \"../data/raw/speaker-recognition-audio-dataset/50_speakers_audio_data\""
      ],
      "metadata": {
        "id": "IdyCOoyh3D_Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "no_speakers_file=5\n",
        "\n",
        "def speakers_list(no_speakers_file ,data_file ):\n",
        "    speaker_l = []\n",
        "\n",
        "    # Get all subfolders in the data_file directory\n",
        "    subfolders = [f.name for f in os.scandir(data_file) if f.is_dir()]\n",
        "\n",
        "    # Check if the requested number of speakers is available\n",
        "    if no_speakers_file > len(subfolders):\n",
        "        raise ValueError(f\"Requested {no_speakers_file} speakers, but only {len(subfolders)} available.\")\n",
        "\n",
        "    # Select the first 'no_speakers_file' subfolders\n",
        "    speaker_l = subfolders[:no_speakers_file]\n",
        "\n",
        "    return speaker_l\n",
        "\n",
        "speaker_list = speakers_list(no_speakers_file,data_file )"
      ],
      "metadata": {
        "id": "A1dwHlle33SO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_mfcc(parent_dir, sub_folders, n_mfcc=13, max_pad_len=1600 , mfcc_window_len= 32):\n",
        "    x = []\n",
        "    y = []\n",
        "\n",
        "    for label, folder in enumerate(sub_folders):\n",
        "        folder_path = os.path.join(parent_dir, folder)\n",
        "\n",
        "        # Loop through each audio file in the speaker's folder\n",
        "        for file_name in os.listdir(folder_path):\n",
        "            if file_name.endswith('.wav'):  # Only process .wav files\n",
        "                file_path = os.path.join(folder_path, file_name)\n",
        "\n",
        "                audio, sr = librosa.load(file_path, sr=None)\n",
        "\n",
        "                # Extract MFCC features\n",
        "                mfcc = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=n_mfcc)\n",
        "\n",
        "                scaler = StandardScaler()\n",
        "                mfcc = scaler.fit_transform(mfcc.T)\n",
        "#                 mfcc.T\n",
        "\n",
        "                # Padding or truncating the MFCC feature array\n",
        "                if mfcc.shape[0] < max_pad_len:\n",
        "                    pad_width = max_pad_len - mfcc.shape[0]\n",
        "                    mfcc = np.pad(mfcc, pad_width=((0, pad_width), (0, 0)), mode='constant')\n",
        "                else:\n",
        "                    mfcc = mfcc[:max_pad_len ,:]\n",
        "\n",
        "                # Slice the MFCC into windows of window_len\n",
        "                num_windows = mfcc.shape[0] // mfcc_window_len\n",
        "                for i in range(num_windows):\n",
        "                    start = i * mfcc_window_len\n",
        "                    end = start + mfcc_window_len\n",
        "                    mfcc_window = mfcc[start:end,: ]\n",
        "                    x.append(mfcc_window)\n",
        "                    y.append(label)\n",
        "\n",
        "  x= np.array(x)\n",
        "  y= np.array(y)\n",
        "  return x,y"
      ],
      "metadata": {
        "id": "tUFRsGeb3Osl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x,y= extract_mfcc(data_file,speaker_list)"
      ],
      "metadata": {
        "id": "b_gi54EV4Eml"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}