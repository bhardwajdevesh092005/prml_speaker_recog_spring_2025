{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd4f0756",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# import pandas as pd\n",
    "import librosa\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import torch\n",
    "import torchaudio\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5082e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)  # For CUDA\n",
    "    torch.cuda.manual_seed_all(seed)  # For multi-GPU\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # Ensures deterministic behavior (optional, can slow things down)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a3a9be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9c1fa73",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file= \"data/processed3/50_speakers_audio_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "656b7124",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_mfcc(parent_dir, sub_folders, n_mfcc=13, max_pad_len=129 , mfcc_window_len= 43):\n",
    "    x = []\n",
    "    y = []\n",
    "    \n",
    "    for label, folder in enumerate(sub_folders):\n",
    "        folder_path = os.path.join(parent_dir, folder)\n",
    "        \n",
    "        # Loop through each audio file in the speaker's folder\n",
    "        for file_name in os.listdir(folder_path):\n",
    "            if file_name.endswith('.wav'):  # Only process .wav files\n",
    "                file_path = os.path.join(folder_path, file_name)\n",
    "                \n",
    "                audio, sr = librosa.load(file_path, sr=None)\n",
    "\n",
    "                # Extract MFCC features\n",
    "                org_mfcc = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=n_mfcc)\n",
    "                delta_mfcc = librosa.feature.delta(org_mfcc)\n",
    "                delta2_mfcc = librosa.feature.delta(org_mfcc , order=2)\n",
    "                mfcc=np.concatenate((org_mfcc, delta_mfcc, delta2_mfcc), axis=0)\n",
    "                \n",
    "                scaler = StandardScaler()\n",
    "                mfcc = scaler.fit_transform(mfcc.T)\n",
    "#                 mfcc.T\n",
    "\n",
    "                # Padding or truncating the MFCC feature array\n",
    "                if mfcc.shape[0] < max_pad_len:\n",
    "                    pad_width = max_pad_len - mfcc.shape[0]\n",
    "                    mfcc = np.pad(mfcc, pad_width=((0, pad_width), (0, 0)), mode='constant')\n",
    "                else:\n",
    "                    mfcc = mfcc[:max_pad_len ,:]\n",
    "\n",
    "                # Slice the MFCC into windows of window_len\n",
    "                num_windows = mfcc.shape[0] // mfcc_window_len\n",
    "                for i in range(num_windows):\n",
    "                    start = i * mfcc_window_len\n",
    "                    end = start + mfcc_window_len\n",
    "                    mfcc_window = mfcc[start:end,: ]\n",
    "                    x.append(mfcc_window)\n",
    "                    speaker_id = int(folder[-2:])\n",
    "                    y.append(speaker_id)\n",
    "    \n",
    "    x= np.array(x)\n",
    "    y= np.array(y)\n",
    "    return x,y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7aa71a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_speakers_file=50\n",
    "\n",
    "def speakers_list(no_speakers_file ,data_file ):\n",
    "    speaker_l = []\n",
    "\n",
    "    # Get all subfolders in the data_file directory\n",
    "    subfolders = [f.name for f in os.scandir(data_file) if f.is_dir()]\n",
    "\n",
    "    # Check if the requested number of speakers is available\n",
    "    if no_speakers_file > len(subfolders):\n",
    "        raise ValueError(f\"Requested {no_speakers_file} speakers, but only {len(subfolders)} available.\")\n",
    "\n",
    "    # Select the first 'no_speakers_file' subfolders\n",
    "    speaker_l = subfolders[:no_speakers_file]\n",
    "\n",
    "    return speaker_l\n",
    "\n",
    "speaker_list = speakers_list(no_speakers_file,data_file )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254b4143",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m x,y= \u001b[43mextract_mfcc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43mspeaker_list\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 13\u001b[39m, in \u001b[36mextract_mfcc\u001b[39m\u001b[34m(parent_dir, sub_folders, n_mfcc, max_pad_len, mfcc_window_len)\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m file_name.endswith(\u001b[33m'\u001b[39m\u001b[33m.wav\u001b[39m\u001b[33m'\u001b[39m):  \u001b[38;5;66;03m# Only process .wav files\u001b[39;00m\n\u001b[32m     11\u001b[39m     file_path = os.path.join(folder_path, file_name)\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m     audio, sr = \u001b[43mlibrosa\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msr\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m     \u001b[38;5;66;03m# Extract MFCC features\u001b[39;00m\n\u001b[32m     16\u001b[39m     org_mfcc = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=n_mfcc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/data/anaconda3/envs/speech/lib/python3.13/site-packages/librosa/core/audio.py:176\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[39m\n\u001b[32m    173\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    174\u001b[39m     \u001b[38;5;66;03m# Otherwise try soundfile first, and then fall back if necessary\u001b[39;00m\n\u001b[32m    175\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m176\u001b[39m         y, sr_native = \u001b[43m__soundfile_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mduration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    178\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m sf.SoundFileRuntimeError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    179\u001b[39m         \u001b[38;5;66;03m# If soundfile failed, try audioread instead\u001b[39;00m\n\u001b[32m    180\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, (\u001b[38;5;28mstr\u001b[39m, pathlib.PurePath)):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/data/anaconda3/envs/speech/lib/python3.13/site-packages/librosa/core/audio.py:209\u001b[39m, in \u001b[36m__soundfile_load\u001b[39m\u001b[34m(path, offset, duration, dtype)\u001b[39m\n\u001b[32m    206\u001b[39m     context = path\n\u001b[32m    207\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    208\u001b[39m     \u001b[38;5;66;03m# Otherwise, create the soundfile object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m209\u001b[39m     context = \u001b[43msf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mSoundFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    211\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m context \u001b[38;5;28;01mas\u001b[39;00m sf_desc:\n\u001b[32m    212\u001b[39m     sr_native = sf_desc.samplerate\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/data/anaconda3/envs/speech/lib/python3.13/site-packages/soundfile.py:690\u001b[39m, in \u001b[36mSoundFile.__init__\u001b[39m\u001b[34m(self, file, mode, samplerate, channels, subtype, endian, format, closefd, compression_level, bitrate_mode)\u001b[39m\n\u001b[32m    687\u001b[39m \u001b[38;5;28mself\u001b[39m._bitrate_mode = bitrate_mode\n\u001b[32m    688\u001b[39m \u001b[38;5;28mself\u001b[39m._info = _create_info_struct(file, mode, samplerate, channels,\n\u001b[32m    689\u001b[39m                                  \u001b[38;5;28mformat\u001b[39m, subtype, endian)\n\u001b[32m--> \u001b[39m\u001b[32m690\u001b[39m \u001b[38;5;28mself\u001b[39m._file = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode_int\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosefd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    691\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mset\u001b[39m(mode).issuperset(\u001b[33m'\u001b[39m\u001b[33mr+\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.seekable():\n\u001b[32m    692\u001b[39m     \u001b[38;5;66;03m# Move write position to 0 (like in Python file objects)\u001b[39;00m\n\u001b[32m    693\u001b[39m     \u001b[38;5;28mself\u001b[39m.seek(\u001b[32m0\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/data/anaconda3/envs/speech/lib/python3.13/site-packages/soundfile.py:1254\u001b[39m, in \u001b[36mSoundFile._open\u001b[39m\u001b[34m(self, file, mode_int, closefd)\u001b[39m\n\u001b[32m   1252\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1253\u001b[39m             file = file.encode(_sys.getfilesystemencoding())\n\u001b[32m-> \u001b[39m\u001b[32m1254\u001b[39m     file_ptr = \u001b[43mopenfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode_int\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_info\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1255\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(file, \u001b[38;5;28mint\u001b[39m):\n\u001b[32m   1256\u001b[39m     file_ptr = _snd.sf_open_fd(file, mode_int, \u001b[38;5;28mself\u001b[39m._info, closefd)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "x,y= extract_mfcc(data_file,speaker_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be99977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Shape: (117052, 43, 39)\n",
      "Test Data Shape: (29264, 43, 39)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "print(\"Training Data Shape:\", x_train.shape)\n",
    "print(\"Test Data Shape:\", x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51add0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape= (43,39)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0dc92f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Initialize encoder and fit on full set of labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)  # Assuming you're predicting on y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69820b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Flatten the data: (n_samples, 32, 13) to (n_samples, 32*13)\n",
    "n_samples_train = x_train.shape[0]\n",
    "x_train_flat = x_train.reshape(n_samples_train, -1)\n",
    "\n",
    "n_samples_test = x_test.shape[0]\n",
    "x_test_flat = x_test.reshape(n_samples_test, -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8283e01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speech",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
